{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Python project skeleton \u00b6 A cookiecutter template for python projects. Docs : https://marcohenriques.github.io/python-project-skeleton Code : https://github.com/marcohenriques/python-project-skeleton Features included \u00b6 Github actions CICD to run formatters, linter, tests. Also support to build and push docker images Dockerfile to ship python apps Documentation with mkdocs using the beautiful material theme Testing using pytest and several plugins Code formatters using black and isort Linters using flake8 (with wemake-python-styleguide ), mypy and shellcheck Python dependencies vulnerabilities scanner using safety pre-commit hooks for some validations Makefile to automate some development tasks poetry to manage your python dependencies Python package pre-configured with: logging module to be easier to manage your loggers per environment setting module using pydantic to help manage your project settings (optional) CLI example using typer Requirements \u00b6 You\u2019ll need to have cookiecutter installed. Installation \u00b6 Run the following command to create a new project, on your current directory: cookiecutter gh:marcohenriques/python-project-skeleton Template inputs \u00b6 The template asks for the following inputs: project_name : The name of the project. This is used to name the project folder. package_name : The name of the package. This is used to name the package folder. project_description : A short description of the project. author_name : The name of the author. author_email : The email of the author. github_username_or_org_name : The github username or organization name. python_version : The python version to use. include_docker : Whether to include docker support. include_notebooks : Whether to include support for jupyter notebooks. include_docs : Whether to include support for documentation. include_cli : Whether to include support for a command line interface.","title":"python-project-skeleton"},{"location":"#python-project-skeleton","text":"A cookiecutter template for python projects. Docs : https://marcohenriques.github.io/python-project-skeleton Code : https://github.com/marcohenriques/python-project-skeleton","title":"Python project skeleton"},{"location":"#features-included","text":"Github actions CICD to run formatters, linter, tests. Also support to build and push docker images Dockerfile to ship python apps Documentation with mkdocs using the beautiful material theme Testing using pytest and several plugins Code formatters using black and isort Linters using flake8 (with wemake-python-styleguide ), mypy and shellcheck Python dependencies vulnerabilities scanner using safety pre-commit hooks for some validations Makefile to automate some development tasks poetry to manage your python dependencies Python package pre-configured with: logging module to be easier to manage your loggers per environment setting module using pydantic to help manage your project settings (optional) CLI example using typer","title":"Features included"},{"location":"#requirements","text":"You\u2019ll need to have cookiecutter installed.","title":"Requirements"},{"location":"#installation","text":"Run the following command to create a new project, on your current directory: cookiecutter gh:marcohenriques/python-project-skeleton","title":"Installation"},{"location":"#template-inputs","text":"The template asks for the following inputs: project_name : The name of the project. This is used to name the project folder. package_name : The name of the package. This is used to name the package folder. project_description : A short description of the project. author_name : The name of the author. author_email : The email of the author. github_username_or_org_name : The github username or organization name. python_version : The python version to use. include_docker : Whether to include docker support. include_notebooks : Whether to include support for jupyter notebooks. include_docs : Whether to include support for documentation. include_cli : Whether to include support for a command line interface.","title":"Template inputs"},{"location":"changelog/","text":"Changelog \u00b6 v0.1.0 (2022-10-25) \u00b6 First version of template","title":"Release Notes"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v010-2022-10-25","text":"First version of template","title":"v0.1.0 (2022-10-25)"},{"location":"quickstart/","text":"Quickstart \u00b6 Before we start generating our project, make sure you already have everything needed. Generate project \u00b6 Run the following command to create a new project, on your current directory: cookiecutter gh:marcohenriques/python-project-skeleton During this process you\u2019ll be prompted for several inputs to configure your project. Setup new generated project \u00b6 First, go to your project directory: cd <my_project_name> Then, to install all the dependencies just run: make install To make sure everything is ok, you can run: make test If all the tests passed without issues, you\u2019re good to go \ud83d\ude80","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"Before we start generating our project, make sure you already have everything needed.","title":"Quickstart"},{"location":"quickstart/#generate-project","text":"Run the following command to create a new project, on your current directory: cookiecutter gh:marcohenriques/python-project-skeleton During this process you\u2019ll be prompted for several inputs to configure your project.","title":"Generate project"},{"location":"quickstart/#setup-new-generated-project","text":"First, go to your project directory: cd <my_project_name> Then, to install all the dependencies just run: make install To make sure everything is ok, you can run: make test If all the tests passed without issues, you\u2019re good to go \ud83d\ude80","title":"Setup new generated project"},{"location":"requirements/","text":"Requirements \u00b6 Rendering project \u00b6 To use this template the only requirement is cookiecutter . Generated project \u00b6 Make Pyenv Poetry (version ~1.2.0) In Linux, make sure you have all required Python dependencies installed: sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev liblzma-dev tk-dev To confirm these system dependencies are configured correctly, on your project directory run: ./scripts/verchew","title":"Requirements"},{"location":"requirements/#requirements","text":"","title":"Requirements"},{"location":"requirements/#rendering-project","text":"To use this template the only requirement is cookiecutter .","title":"Rendering project"},{"location":"requirements/#generated-project","text":"Make Pyenv Poetry (version ~1.2.0) In Linux, make sure you have all required Python dependencies installed: sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev liblzma-dev tk-dev To confirm these system dependencies are configured correctly, on your project directory run: ./scripts/verchew","title":"Generated project"},{"location":"tools_included/docker/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Docker"},{"location":"tools_included/documentation/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Documentation"},{"location":"tools_included/formatters/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Formatters"},{"location":"tools_included/github_actions/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Github Actions"},{"location":"tools_included/ide_settings/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"IDE Settings"},{"location":"tools_included/linters/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Linters"},{"location":"tools_included/logging/","text":"Logging \u00b6 For logging, we\u2019re using a centralized file ( logging_config.yaml ), under <my_project_name>/src/configs/<your_environment> (where your_environment is defined by the env var APP_ENV , defaults to local ). In this file, you can define your log formatters , filters , handlers and your root and specific loggers (including from other packages). To better understand how to configure it, you can check the logging-cookbook . Custom logging objects \u00b6 We can define custom logging object to be used on our configurations file. To defined these object, the implementation should be in the src/<my_package_name>/logging_setup.py file to be properly loaded. Handlers \u00b6 For the native handlers please check logging.handlers . Other handler you might find useful is watchtower , which allows you send your logs to AWS CloudWatch Logs. Filters \u00b6 To define a custom filter you\u2019ll need to create a subclass of logging.Filter inside src/<my_package_name>/logging_setup.py . One example of a filter could be: class InfoFilter ( logging . Filter ): \"\"\"Example of a simple logger filter, to only select logs with level INFO.\"\"\" def filter ( self , record : logging . LogRecord ) -> bool : \"\"\"Determine if the specified record is to be logged. Returns True if the record should be logged, or False otherwise. If deemed appropriate, the record may be modified in-place. Args: record (logging.LogRecord): log record Returns: bool: the filter predicate execution \"\"\" return record . levelno == logging . INFO Then to use the filter, on you logging_config.yaml , configure it like: formatters : standard : format : \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" filters : infoFilter : () : <my_package_name>.logging_setup.InfoFilter handlers : console : class : logging.StreamHandler level : DEBUG formatter : standard stream : ext://sys.stdout cloudwatch : class : watchtower.CloudWatchLogHandler level : INFO formatter : standard log_group : /custom/apps/<my_package_name> stream_name : app log_group_retention_days : 90 info_file : class : logging.handlers.RotatingFileHandler level : INFO formatter : standard filename : /tmp/info.log maxBytes : 10485760 backupCount : 20 filters : [ infoFilter ] # example of a log filter encoding : utf8 In this case, the handler info_file will only contains INFO logging records. Loggers \u00b6 Note: when defining loggers be mindful about the parameter propagate . As a rule of thumb, if you attach an handler to a logger, you will typically want to set this parameter to false, if not, the log record will be passed to the handlers of higher level (ancestor) loggers. For instances: root : level : NOTSET # if set, this will be the default logging level for all packages not cover in loggers section handlers : [ console ] propagate : no loggers : <my_package_name> : level : WARNING handlers : [ console ] propagate : no <my_package_name>.some_package_a : level : DEBUG handlers : [ info_file ] propagate : no <my_package_name>.some_package_b : level : DEBUG handlers : [ info_file ] <my_package_name>.some_package_c : level : INFO <my_package_name>.some_package_d : # level: NOTSET handlers : [ info_file ] Lets see what\u2019s happening in there 4 last loggers: <my_package_name>.some_package_a : log records are send only to info_file handler, with level DEBUG <my_package_name>.some_package_b : log records are send to info_file and console (ancestor logger) handlers, with level DEBUG <my_package_name>.some_package_c : log records are send only to console (ancestor logger) handler, with level INFO <my_package_name>.some_package_d : log records are send to info_file and console (ancestor logger) handlers, with level WARNING (ancestor logger level)","title":"Logging"},{"location":"tools_included/logging/#logging","text":"For logging, we\u2019re using a centralized file ( logging_config.yaml ), under <my_project_name>/src/configs/<your_environment> (where your_environment is defined by the env var APP_ENV , defaults to local ). In this file, you can define your log formatters , filters , handlers and your root and specific loggers (including from other packages). To better understand how to configure it, you can check the logging-cookbook .","title":"Logging"},{"location":"tools_included/logging/#custom-logging-objects","text":"We can define custom logging object to be used on our configurations file. To defined these object, the implementation should be in the src/<my_package_name>/logging_setup.py file to be properly loaded.","title":"Custom logging objects"},{"location":"tools_included/logging/#handlers","text":"For the native handlers please check logging.handlers . Other handler you might find useful is watchtower , which allows you send your logs to AWS CloudWatch Logs.","title":"Handlers"},{"location":"tools_included/logging/#filters","text":"To define a custom filter you\u2019ll need to create a subclass of logging.Filter inside src/<my_package_name>/logging_setup.py . One example of a filter could be: class InfoFilter ( logging . Filter ): \"\"\"Example of a simple logger filter, to only select logs with level INFO.\"\"\" def filter ( self , record : logging . LogRecord ) -> bool : \"\"\"Determine if the specified record is to be logged. Returns True if the record should be logged, or False otherwise. If deemed appropriate, the record may be modified in-place. Args: record (logging.LogRecord): log record Returns: bool: the filter predicate execution \"\"\" return record . levelno == logging . INFO Then to use the filter, on you logging_config.yaml , configure it like: formatters : standard : format : \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" filters : infoFilter : () : <my_package_name>.logging_setup.InfoFilter handlers : console : class : logging.StreamHandler level : DEBUG formatter : standard stream : ext://sys.stdout cloudwatch : class : watchtower.CloudWatchLogHandler level : INFO formatter : standard log_group : /custom/apps/<my_package_name> stream_name : app log_group_retention_days : 90 info_file : class : logging.handlers.RotatingFileHandler level : INFO formatter : standard filename : /tmp/info.log maxBytes : 10485760 backupCount : 20 filters : [ infoFilter ] # example of a log filter encoding : utf8 In this case, the handler info_file will only contains INFO logging records.","title":"Filters"},{"location":"tools_included/logging/#loggers","text":"Note: when defining loggers be mindful about the parameter propagate . As a rule of thumb, if you attach an handler to a logger, you will typically want to set this parameter to false, if not, the log record will be passed to the handlers of higher level (ancestor) loggers. For instances: root : level : NOTSET # if set, this will be the default logging level for all packages not cover in loggers section handlers : [ console ] propagate : no loggers : <my_package_name> : level : WARNING handlers : [ console ] propagate : no <my_package_name>.some_package_a : level : DEBUG handlers : [ info_file ] propagate : no <my_package_name>.some_package_b : level : DEBUG handlers : [ info_file ] <my_package_name>.some_package_c : level : INFO <my_package_name>.some_package_d : # level: NOTSET handlers : [ info_file ] Lets see what\u2019s happening in there 4 last loggers: <my_package_name>.some_package_a : log records are send only to info_file handler, with level DEBUG <my_package_name>.some_package_b : log records are send to info_file and console (ancestor logger) handlers, with level DEBUG <my_package_name>.some_package_c : log records are send only to console (ancestor logger) handler, with level INFO <my_package_name>.some_package_d : log records are send to info_file and console (ancestor logger) handlers, with level WARNING (ancestor logger level)","title":"Loggers"},{"location":"tools_included/makefile/","text":"Makefile \u00b6 The project includes a Makefile to help automate some tasks. These tasks can be grouped into sections. System Dependencies \u00b6 To check if you have all required tools: make doctor Project Dependencies \u00b6 Tasks that help you setup your environment (create environment, install packages and tools\u2026) install \u00b6 make install This will should be the first command to prepare your environment. It will setup several things: create a .python-version file, that will tell pyenv which python version to use. Behind the scenes, it will look at the python version you select during project generation (which is stored in the variable PYTHON_VERSION on your Makefile), and will search for the latest version available and use it (make sure to have pyenv up to date) poetry will use this version and create your virtual environment on the project root ( .venv folder), and then install the project core , dev and test dependencies if there\u2019s no git initialization in the project, it will perform a git init , if there is, it will be skipped next it will install the pre-commit hooks and install the git message template install-jupyter \u00b6 make install-jupyter Install the dependencies to run jupyter notebooks. This target is only available if selected in project setup ( include_notebooks ). install-docs \u00b6 make install-docs Install the dependencies to build documentation. This target is only available if selected in project setup ( include_docs ). requirements.txt \u00b6 make requirements.txt This will update/generate the project requirements.txt , based on the installed dependencies from poetry. Checks \u00b6 Tasks to run linters, formatters and python dependencies vulnerabilities scanner format \u00b6 make format Runs black and isort on your src and tests directory. check-packages \u00b6 make check-packages Runs checks on packages: - Checks the validity of the pyproject.toml file - Verify installed packages have compatible dependencies - Run safety check to find vulnerabilities in Python dependencies lint \u00b6 make -k lint Runs mypy and flake8 on your src and tests directory, and shellcheck on shell files. You can also run each check individually: make mypy , make flake8 and make shellcheck . check \u00b6 make -k check Runs both check-packages and lint targets. pre-commit \u00b6 make pre-commit Runs the pre-commit checks on all files. Tests \u00b6 Tasks related with testing. test \u00b6 make test Runs the tests with pytest . As we\u2019re using pytest-randomly to shuffle the tests, if the last run of the tests fails, it will run the test with the same random seed first, and then, if the tests pass, it will run with a new one. read-coverage \u00b6 make read-coverage Opens the coverage report for the last pytest run. Documentation \u00b6 Tasks related with documentation. This section is only available if selected in project setup ( include_docs ). build-docs \u00b6 make build-docs Generate mkdocs documentation locally. The first this target is executed, it will run the target install-docs before. docs \u00b6 make docs Build docs and serve them. Build \u00b6 Tasks related with builds. dist \u00b6 make dist Builds the package, as a tarball and a wheel. Cleanup \u00b6 Tasks to cleanup. clean \u00b6 make clean Delete all generated and temporary files. clean-all \u00b6 make clean-all Delete virtual environment and all generated and temporary files. Docker \u00b6 Tasks related with docker. This section is only available if selected in project setup ( include_docker ). build-docker \u00b6 make build-docker Build docker image. run-docker \u00b6 make run-docker Run docker container for the built image. Other Tasks \u00b6 ci \u00b6 make -k ci Run targets format , check , test and build-docs (if selected) jupyter \u00b6 make jupyter Run jupyter notebooks on the notebooks directory (it will be created if it doesn\u2019t exist). The first this target is executed, it will run the target install-jupyter before.","title":"Makefile"},{"location":"tools_included/makefile/#makefile","text":"The project includes a Makefile to help automate some tasks. These tasks can be grouped into sections.","title":"Makefile"},{"location":"tools_included/makefile/#system-dependencies","text":"To check if you have all required tools: make doctor","title":"System Dependencies"},{"location":"tools_included/makefile/#project-dependencies","text":"Tasks that help you setup your environment (create environment, install packages and tools\u2026)","title":"Project Dependencies"},{"location":"tools_included/makefile/#install","text":"make install This will should be the first command to prepare your environment. It will setup several things: create a .python-version file, that will tell pyenv which python version to use. Behind the scenes, it will look at the python version you select during project generation (which is stored in the variable PYTHON_VERSION on your Makefile), and will search for the latest version available and use it (make sure to have pyenv up to date) poetry will use this version and create your virtual environment on the project root ( .venv folder), and then install the project core , dev and test dependencies if there\u2019s no git initialization in the project, it will perform a git init , if there is, it will be skipped next it will install the pre-commit hooks and install the git message template","title":"install"},{"location":"tools_included/makefile/#install-jupyter","text":"make install-jupyter Install the dependencies to run jupyter notebooks. This target is only available if selected in project setup ( include_notebooks ).","title":"install-jupyter"},{"location":"tools_included/makefile/#install-docs","text":"make install-docs Install the dependencies to build documentation. This target is only available if selected in project setup ( include_docs ).","title":"install-docs"},{"location":"tools_included/makefile/#requirementstxt","text":"make requirements.txt This will update/generate the project requirements.txt , based on the installed dependencies from poetry.","title":"requirements.txt"},{"location":"tools_included/makefile/#checks","text":"Tasks to run linters, formatters and python dependencies vulnerabilities scanner","title":"Checks"},{"location":"tools_included/makefile/#format","text":"make format Runs black and isort on your src and tests directory.","title":"format"},{"location":"tools_included/makefile/#check-packages","text":"make check-packages Runs checks on packages: - Checks the validity of the pyproject.toml file - Verify installed packages have compatible dependencies - Run safety check to find vulnerabilities in Python dependencies","title":"check-packages"},{"location":"tools_included/makefile/#lint","text":"make -k lint Runs mypy and flake8 on your src and tests directory, and shellcheck on shell files. You can also run each check individually: make mypy , make flake8 and make shellcheck .","title":"lint"},{"location":"tools_included/makefile/#check","text":"make -k check Runs both check-packages and lint targets.","title":"check"},{"location":"tools_included/makefile/#pre-commit","text":"make pre-commit Runs the pre-commit checks on all files.","title":"pre-commit"},{"location":"tools_included/makefile/#tests","text":"Tasks related with testing.","title":"Tests"},{"location":"tools_included/makefile/#test","text":"make test Runs the tests with pytest . As we\u2019re using pytest-randomly to shuffle the tests, if the last run of the tests fails, it will run the test with the same random seed first, and then, if the tests pass, it will run with a new one.","title":"test"},{"location":"tools_included/makefile/#read-coverage","text":"make read-coverage Opens the coverage report for the last pytest run.","title":"read-coverage"},{"location":"tools_included/makefile/#documentation","text":"Tasks related with documentation. This section is only available if selected in project setup ( include_docs ).","title":"Documentation"},{"location":"tools_included/makefile/#build-docs","text":"make build-docs Generate mkdocs documentation locally. The first this target is executed, it will run the target install-docs before.","title":"build-docs"},{"location":"tools_included/makefile/#docs","text":"make docs Build docs and serve them.","title":"docs"},{"location":"tools_included/makefile/#build","text":"Tasks related with builds.","title":"Build"},{"location":"tools_included/makefile/#dist","text":"make dist Builds the package, as a tarball and a wheel.","title":"dist"},{"location":"tools_included/makefile/#cleanup","text":"Tasks to cleanup.","title":"Cleanup"},{"location":"tools_included/makefile/#clean","text":"make clean Delete all generated and temporary files.","title":"clean"},{"location":"tools_included/makefile/#clean-all","text":"make clean-all Delete virtual environment and all generated and temporary files.","title":"clean-all"},{"location":"tools_included/makefile/#docker","text":"Tasks related with docker. This section is only available if selected in project setup ( include_docker ).","title":"Docker"},{"location":"tools_included/makefile/#build-docker","text":"make build-docker Build docker image.","title":"build-docker"},{"location":"tools_included/makefile/#run-docker","text":"make run-docker Run docker container for the built image.","title":"run-docker"},{"location":"tools_included/makefile/#other-tasks","text":"","title":"Other Tasks"},{"location":"tools_included/makefile/#ci","text":"make -k ci Run targets format , check , test and build-docs (if selected)","title":"ci"},{"location":"tools_included/makefile/#jupyter","text":"make jupyter Run jupyter notebooks on the notebooks directory (it will be created if it doesn\u2019t exist). The first this target is executed, it will run the target install-jupyter before.","title":"jupyter"},{"location":"tools_included/poetry/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Poetry"},{"location":"tools_included/pre-commit/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"pre-commit"},{"location":"tools_included/tests/","text":"\ud83d\udd28\ud83d\udc77\u200d\u2642\ufe0f","title":"Tests"}]}